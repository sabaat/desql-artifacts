# Artifact: DeSQL: Interactive Debugging of SQL in Data-Intensive Scalable Computing
## 1. Pre-requisites
This manual assumes `docker` is installed and set up properly on your device.\
These instructions have been tested with the following configurations: 
* **Ubuntu:** 20.04.6 LTS\
  **Docker:** 24.0.2, build cb74dfc
## 2. Creating the Docker Image
Clone this repository:
```
git clone https://github.com/SEED-VT/DeSQL.git
```
Navigate into the repository folder:
```
cd DeSQL
```
Build the docker image using:
> **_NOTE:_** If you receive a permission denied error you will need to prefix all docker commands with `sudo`. Whether or not this is needed depends on how docker is configured on your machine. A docker vulnerability warning at the end is okay and will not be an issue.
```
docker build -t my-custom-spark:latest -f dist/kubernetes/dockerfiles/spark/Dockerfile .
```
```
docker compose up -d
```
> **_TROUBLESHOOTING:_** If any of the above commands fails try restarting the docker service using: `sudo systemctl restart docker`

## 3. Running the DeSQL
```
docker exec -it spark-local-container /opt/spark/bin/spark-submit --class DeSqlPackage.SQLTest.SQLTest --master “local[*]” --conf spark.some.config.option=some-value /opt/spark/app/desqlpackage_2.12-0.1.0-SNAPSHOT.jar /opt/spark/queries/query4.sql
```

Here you can run all 10 queries used by DeSQL.

> **_Expected Observation:_** The DeSQL will start and logs can be seen on your console. Once the DeSQL starts, User can check the output of DeSQL at `http://localhost:4040/debugger/`. This UI of the DeSQL displays all possible sub-queries of the original query along with their respective data as it appears within Spark computations. Alongside the original query, it also displays the query plan generated by the spark for that query. Users can click any node of that plan with available sub-queries (green nodes) to see the node's respective subquery and data.
